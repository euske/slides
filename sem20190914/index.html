<!DOCTYPE html>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<html>
<head>
<title>権藤研 講習会資料 2019/09/14 Python + SQLiteを使った実験データ処理</title>
<style><!--
body { line-height: 1.5; }
h1 { border-bottom: solid 4px #000080; }
h2 { border-bottom: solid 2px #000080; }
h3 { border-bottom: solid 1px #000080; }
table { border-collapse: collapse; margin: 0.5em; }
kbd { border: 1px solid black; padding: 4px; margin: 4px; }
code { font-weight: bold; color: purple; }
em { color: blue; }
.h { text-align: right; }
.q { border: 2px solid black; padding: 1em; margin: 1em; }
.figure { border: 1px solid black; text-align: center; padding: 0.5em; margin: 0.5em; }
.comment { color: green; }
.exp { border: 1px solid black; padding: 1em; margin: 1em; }
pre { border: 1px solid black; padding: 0.3em; }
--></style>
<script>
function doit() {
    if (document.baseURI.startsWith("file:")) {
        for (e of document.getElementsByClassName("offline")) {
            if (e.tagName == "IMG") {
                let i = e.src.lastIndexOf("/");
                let src = "./"+e.src.substr(i+1);
                console.log("offline: "+e.src+" -> "+src);
                e.src = src;
            }
        }
    }
}
</script>
</head>
<body>

<div class=nav>
<a href="../index.html">&lt; もどる</a>
</div>
<h1>Python + SQLiteを使った実験データ処理</h1>

<div class=h>
権藤研 講習会資料 2019/09/14, 09/16, 10/07<br>
新山
</div>

<ul>
<li> <a href="#warmup">0. ウォームアップ問題</a>
<li> <a href="#shellscript">1. UNIXスクリプト処理の基本</a>
<li> <a href="#datamgmt">2. 実験データの管理</a>
<li> <a href="#bigdata">3. 大量のデータを蓄積・処理する場合のTips</a>
<li> <a href="#serialization">4. データのSerializationについて</a>
<li> <a href="#python">5. Python から CSV/JSON/SQLite を使う</a>
<li> <a href="#vsm">6. Vector Space Model を使った類似度計算</a>
<li> <a href="#clustering">7. 類似度をもちいたクラスタリングの実装</a>
<li> <a href="#warmup2">7.99. ウォームアップ問題 (その2)</a>
<li> <a href="#dtree">8. Python による決定木の実装</a>
<li> <a href="#naivebayes">9. Python による Naive Bayes の実装</a>
</ul>


<h2 id="warmup">0. ウォームアップ問題</h2>
<p>
( ) 内はおおまかな目安時間です。
<ol>
<li> <a href="https://www.python.org/downloads/">Python 3.7</a> をインストールせよ。(5分)
<li> 以下のようなCSVファイルから単語と出現回数を読み込み、
回数が多い順にソートして表示するプログラムを書け。
なお、同じ単語が複数回出てきた場合は、それらの合計を使用するものとする: (15分)
<pre>
foo,3
baa,1
john,5
foo,1
</pre>
出力例:
<pre>
john,5
foo,4
baa,1
</pre>
<li> <a href="https://www.sqlite.org/download.html">SQLite3</a> をインストールせよ。(5分)
<li> 以下の表を作成し値を入力する <a href="https://www.sqlite.org/lang.html">SQL</a> を書け。(10分)
<table border>
<tr><th>Id</th><th>Name</th><th>Score</th></tr>
<tr><td>1</td><td>Alcie</td><td>100</td></tr>
<tr><td>2</td><td>Bob</td><td>50</td></tr>
<tr><td>3</td><td>Carol</td><td>75</td></tr>
</table>
<li> 上の表から、Scoreが50点であるような行を表示する SQL を書け。(5分)
<li> <code>a001.txt</code>, <code>a002.txt</code>, ... という名前のついた
複数のファイルがあるとする。これらの名前を一括して
<code>a001.html</code>, <code>a002.html</code>, ... に変更するような
シェルスクリプトを書け。 (5分)
<li> 上のスクリプトで、ファイル名の一覧があらかじめ決まっておらず、
あるテキストファイル <code>files.txt</code> 中に一行ずつ書かれている場合は
スクリプトをどう変更すべきか。(5分)
</ol>


<h2 id="shellscript">1. UNIXスクリプト処理の基本</h2>

<h3>1.1. シェルの基本</h3>

<p>
特殊な記号 (<kbd>{</kbd>, <kbd>}</kbd>, <kbd>$</kbd>, <kbd>*</kbd>, <kbd>;</kbd>) を
引数に渡す場合は <kbd>'〜'</kbd> で囲む。

<div class=q>
<strong>演習.</strong>
カレントディレクトリの中にある「<code>-t</code>」というファイル中から
<code>*</code> という文字列を検索する <code>grep</code> コマンドを書け。
</div>

<h3>1.2. 変数の活用</h3>

<blockquote><pre>
a="foo"
echo "$a"
b="$a $a"
c='$a $a'
d='$a '"$a"
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
シェル変数と環境変数の違いは何か?
</div>

<h3>1.3. Historyを活用する</h3>
<p>
「こんなコマンドを実行したはずなんだけど、なんだっけ」

<blockquote><pre>
$ <strong>history | grep <em>なんか</em></strong>
</pre></blockquote>
<p>
<strong>注意:</strong>
historyファイルはときどき消されることがある。

<h4>過去のコマンドラインをすべて記録しておく</h4>
<blockquote><pre>
function _prompt_cmd {
    local s=$?
    echo "`date '+%Y-%m-%d %H:%M:%S'` $HOSTNAME:$$ $PWD ($s) " \
         "`history 1`" &gt;&gt; $MYHISTFILE
}
PROMPT_COMMAND=_prompt_cmd
</pre></blockquote>
<p>
コマンドラインの記録は、そのまま実験ノートにもなる。
あとで実験手順を再現したいときに参考になる。

<h3>1.4. パイプの使い方</h3>

<div class=q>
<strong>演習.</strong>
以下のコマンドラインを順に実行し、
つぎの表現が何をするか予測せよ。
</div>

<blockquote><pre>
$ <strong>ls -l</strong>
$ <strong>ls -l | wc</strong>
$ <strong>ls -l | sort</strong>
$ <strong>ls -l | sort -k4</strong>
$ <strong>ls -l | sort -k4 -r</strong>
$ <strong>ls -l | sort -k4 -r -n</strong>
$ <strong>ls -l | awk '{print $5;}'</strong>
$ <strong>ls -l | awk '{a+=$5;}'</strong>
$ <strong>ls -l | awk 'BEGIN{a=0;} {a+=$5;} END{print(a);}'</strong>
$ <strong>ls -l | awk '/euske/ {print $4;}' | uniq</strong>
$ <strong>ls -l | awk '/euske/ {print $4;}' | uniq -c</strong>
$ <strong>ls -l | awk '/euske/ {print $4;}' | uniq -c | wc</strong>
</pre></blockquote>

<blockquote><pre>
$ <strong>find ~</strong>
$ <strong>find ~ -type f</strong>
$ <strong>find ~ -type f | grep test</strong>
$ <strong>find ~ -type f | grep -i test</strong>
$ <strong>find ~ -type f | grep -i test | wc</strong>
$ <strong>find ~ -type f -name '*test*'</strong>
$ <strong>find ~ -type d -ctime -3</strong>
$ <strong>find ~ -type d -mtime +3</strong>
$ <strong>find ~ -type d -mtime +3</strong>
</pre></blockquote>

<h3>1.5. shスクリプトの基本</h3>

<p>
shスクリプトはこの行から始める。
<blockquote><pre>
#!/bin/sh
  または
#!/bin/bash
</pre></blockquote>

<blockquote><pre>
$ <strong>chmod 755 foo.sh</strong>
</pre></blockquote>

<h4>コマンドライン引数の扱い</h4>

<blockquote><pre>
echo "$0"
a=$1
shift
b=$1
c="$@"
</pre></blockquote>

<h4>あるプロセスの標準出力を値として使う</h4>

<blockquote><pre>
`<em>コマンド</em>`
  または
$(<em>コマンド</em>)
</pre></blockquote>

<h4>よく使う制御構造</h4>

<blockquote><pre>
if <em>式</em>; then ...; else ...; fi
</pre></blockquote>

<blockquote><pre>
if <em>式</em>; then
    ...
else
    ...
fi
</pre></blockquote>

<blockquote><pre>
for <em>変数</em> in <em>式</em>; do
    ...
done
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
与えられた引数を1行ずつ表示するシェルスクリプトを書け。
ただし、その行が <kbd>foo</kbd> であるときのみ、
<kbd>bar</kbd> と表示すること。
</div>

<blockquote><pre>
while read <em>変数</em>; do
    ...
done
</pre></blockquote>

<blockquote><pre>
case <em>式</em> in
<em>パターン1</em>)
    ...
    ;;
<em>パターン2</em>)
    ...
    ;;
*)
    ...
    ;;
esac
</pre></blockquote>

<h3>1.6. xargs を使う</h3>

<blockquote><pre>
$ <strong>cat files.txt</strong>
a.txt
b.txt
c.txt
$ <strong>cat files.txt | xargs echo</strong>
$ <strong>cat files.txt | xargs cat</strong>
$ <strong>find -type d | xargs ls</strong>
</pre></blockquote>

<h3>1.7. 実験パイプラインの設計</h3>

<p>
UNIXプログラムのお約束:
<ul>
<li> 出力は、標準出力に。
<li> ログは、標準エラー出力に。
</ul>

<ul>
<li> できるだけ各コマンドが
<strong>ひとつだけ</strong>のことをするように設計する。
<li> できるだけ標準入力から入力を受けとり、標準出力に結果を表示する:
<blockquote><pre>
$ <strong>cmd1 input.txt | cmd2 | cmd3 &gt; output.txt</strong>
</pre></blockquote>
<li> 途中結果を確認したい場合:
<blockquote><pre>
$ <strong>cmd1 input.txt</strong>
</pre></blockquote>
<li> 途中結果を保存しておき、後で続きをやりたい場合:
<blockquote><pre>
$ <strong>cmd1 input.txt &gt; temp.txt</strong>
$ <strong>cmd2 &lt; temp.txt | cmd3 &gt; output.txt</strong>
</pre></blockquote>
<li> 途中結果をモニタしたい場合:
<blockquote><pre>
$ <strong>cmd1 input.txt | tee temp.txt | cmd2 | cmd3 &gt; output.txt</strong>
</pre></blockquote>
</ul>

<h4>a. フィルタとして設計する場合</h4>
<blockquote><pre>
$ <em>コマンド</em> [<em>オプション</em>] &lt; <em>入力ファイル</em> &gt; <em>出力ファイル</em>
</pre></blockquote>

<h4>b. 1つのファイルを入力する場合</h4>
<blockquote><pre>
$ <em>コマンド</em> [<em>オプション</em>] <em>入力ファイル</em>
</pre></blockquote>

<h4>c. 可変個のファイルを入力する場合 (理想形)</h4>
<blockquote><pre>
$ <em>コマンド</em> [<em>オプション</em>] <em>入力ファイル1</em> <em>入力ファイル2</em> ...
</pre></blockquote>
ファイル名が与えられない場合は標準入力を使用する。
<p>
こうしておくと
<blockquote><pre>
$ <strong>find ... | xargs <em>コマンド</em> [<em>オプション</em>]</strong>
</pre></blockquote>
のようにできる。
<p>
また、実験パラメータの変更はコードをじかに変更するのではなく、
コマンドラインオプションとして処理すること。
<h4>例</h4>
<blockquote><pre>
$ <strong>exp1 -a1 -p2 -k0 input.txt &gt; output_a1_p2_k0.txt</strong>
$ <strong>exp1 -a2 -p3 -k5 input.txt &gt; output_a2_p3_k5.txt</strong>
...
</pre></blockquote>

<h4>ログに関する注意</h4>
<p>
ログは、たとえ人間が読む場合でも、
なるべく機械的に処理できるようにしておくこと。
(grep/awk 等でのおおまかな統計が簡単にとれる。)
<ul>
<li> ×: <code>print("kokodayo", x, y)</code>
<li> ○: <code>print(f"DEBUG: data read complete: x={x}, y={y}.")</code>
</ul>

<h4>長く走らせるスクリプト</h4>

<blockquote><pre>
#!/bin/sh
exec &lt;/dev/null
exec &gt;log
exec 2&gt;&amp;1
renice +20 -p $$

echo "*** START `date` ***"
/usr/bin/time -v <em>実際のコマンド</em>
echo "*** END `date` ***"
</pre></blockquote>

<h3>1.8. Pythonスクリプトの定石</h3>
<p>
Pythonスクリプトは慣例によりこの行から始める。
<blockquote><pre>
#!/usr/bin/env python
</pre></blockquote>
<p>
だいたい以下のようなパターンで書くと、
上に示した「お約束」に沿ったコマンドになる。
<blockquote><pre>
import sys
import fileinput

def doit(args):
    for line in fileinput.input(args):
        print(line)
    return

def main(argv):
    import getopt
    def usage():
        print('usage: %s [-d] [-o output] [file ...]' % argv[0])
        return 100
    try:
        (opts, args) = getopt.getopt(argv[1:], 'do:')
    except getopt.GetoptError:
        return usage()
    debug = 0
    output = None
    for (k, v) in opts:
        if k == '-d': debug += 1
        elif k == '-o': output = v
    return doit(args)

if __name__ == '__main__': sys.exit(main(sys.argv))
</pre></blockquote>

<ul>
<li> <code>sys.argv</code> でコマンドライン引数を取得。
<li> <code>getopt</code> でオプションを取得。
<li> <code>main()</code> 関数はコマンドラインの解析のみをおこない
  実際の処理は <code>doit()</code> 関数に正式なパラメータを渡してやらせる。
  (これにより、他モジュールから利用することが可能)
</ul>

<blockquote><pre>
$ <strong>python test.py input.txt</strong>
  または
$ <strong>test.py input.txt</strong>
  または
$ <strong>cat input.txt | test.py</strong>
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
<ol>
<li> 上のプログラムを書き換え、
  変数 <code>debug</code> により <code>doit()</code> 内の
  なんらかの挙動が変わるようにせよ。
<li> 引数をとる <code>-p</code> オプションを追加せよ:
<blockquote><pre>
$ <strong>test.py -p 4 input.txt</strong>
</pre></blockquote>
</ol>
</div>


<h2 id="datamgmt">2. 実験データの管理</h2>

<h3>2.1. ファイル名のつけ方</h3>
<p>
基本戦略は、シェルのワイルドカード (<kbd>*</kbd>) で
ある条件をもったファイルだけを簡単に指定できるようにすることである。
<ul>
<li> <strong>名前</strong>は重要である。できるだけ意味がわかる名前にすること。
  (さもないと、あとでワケわかんなくなる)
<li> 規則的にする。(日付・条件・用途によって予測可能にする)
<ul>
  <li> <code>src_exp1_ver2.csv</code>
  <li> <code>result-v4-20190803-temp.txt</code>
  <li> <code>out.3cddd4d137ad4f794a8ccf0763b4d5a6450934b5</code>
</ul>
<li> 一定の prefix をつける。
<ul>
  <li> ×: <code>jikken</code>, <code>jiken2</code>, ..., <code>kekka3</code>
  <li> ○: <code>jikken_1</code>, <code>jikken_2</code>, ..., <code>jikken_3</code>
</ul>
<li> データの種類・用途によって拡張子を変える。
  <ul>
    <li> <code>jikken_2.input</code>
    <li> <code>jikken_2.output</code>
    <li> <code>jikken_2.graph</code>
    <li> <code>jikken_2.graph.svg</code>
  </ul>
<li> 数値が入る場合は、桁数を揃える。
<ul>
  <li> ×: <code>f1</code>, <code>f2</code>, ..., <code>f443</code>
  <li> ○: <code>f0001</code>, <code>f0002</code>, ..., <code>f0443</code>
</ul>
</ul>

<h3>2.2. ディレクトリ構造</h3>
<p>
基本的にUNIXのファイル名は<strong>逐次探索</strong>である。
したがって、あまり1個のディレクトリに沢山のファイルを置くと遅くなる
(せいぜい1000個程度)。
<p>
それからパス名が長くなりすぎると見にくいし、入力も大変。
<ol>
<li> データの種類・用途ごとにまとめる (<code>input/</code>, <code>output/</code>)
<li> 日付ごとにまとめる (<code>s201909121012/</code>, ...)
<li> 実験条件ごとにまとめる (<code>data_seg01_p3_q4/</code>, ...)
<li> 1., 2., 3. の混合 (<code>data_201909121012_seg01_p3_input</code>, ...)
</ol>


<h2 id="bigdata">3. 大量のデータを蓄積・処理する場合のTips</h2>
<p>
可能なかぎり stream可能にする (データ形式が重要)。
<p>
なるべく高速に parse できる形式にする。
(しかし自己流バイナリ形式はおすすめしない)
<p>
変更頻度が少ないものはディスク上に置いてもよい。
<p>
参照頻度が多くても、シーク可能ならディスク上に置けるかもしれない。
(OSがキャッシュするので)

<h4>高速化のためのよくある手段</h4>
<ul>
<li> 計算をサボる。(事前条件の強化)
<li> 計算をごまかす。(近似値の使用)
<li> 計算を後回しにする/先にやっておく。(キャッシュ・lookup tableの使用)
</ul>

<h2 id="serialization">4. データのSerializationについて</h2>

<h3>4.1. 考慮する要素</h3>
<ul>
<li> 複雑さ (数値、テキスト、構造体)
<li> データ量 (オンメモリ, 10GBytes, 1TBytes)
<li> 変更する頻度 (0回 / 1回以上)
<li> 参照パターン (シークの要・不要)
<li> 共有度 (複数のプロセス、タスク、マシン間で?)
<li> キャッシュ可能性
<li> 堅牢性 (データの一部が崩れても全体に影響を与えないか?)
</ul>
<p>
<strong>重要:</strong>
できるだけ既存のツール・ライブラリで処理できるようにする。

<h3>4.2. テキストファイル (自分フォーマット)</h3>
<p>
おすすめしない。
もしやるとしたら、parseが簡単にできるようにすること。

<h4>新山がときどき使っているフォーマット</h4>
<blockquote><pre>
# コメント
+キー1 バリュー1
+キー2 バリュー2
(空行がレコード区切り)
</pre></blockquote>

<ul>
<li> 利点: 特定のフィールドが grep で簡単に見れる。データに注釈が入れられる。
Pythonで簡単に解析可能。エディタで修正が簡単。
<li> 欠点: 自己流。
1行 = 1レコードではない。
</ul>

<blockquote><pre>
rec = {}
for line in fp:
    line = line.strip()
    if line.startswith('#'): continue
    if line.startswith('+'):
        (k,_,v) = line.partition(' ')
        rec[k] = v
    elif not line:
        yield rec
        rec = {}
</pre></blockquote>

<h3>4.3. バイナリファイル (自分フォーマット)</h3>
<p>
<strong>超</strong>おすすめしない。
<p>
簡単なデータだけならいいかも
(たとえば 32ビット列の羅列ひたすら1G個とか)。

<h3>4.4. よく知られている形式 (おすすめ)</h3>

<h4>CSV</h4>
<ul>
<li> 利点:
簡単。テキスト。
Excelで編集できる。
<li> 欠点:
微妙に仕様が標準化されていない。
(とくに <kbd>&quot;</kbd> や <kbd>,</kbd> が入ったセルの場合)
巨大なデータには向かない。シーク不可。書き換え不可。
</ul>

<h4>JSON</h4>
<ul>
<li> 利点:
簡単。テキスト。言語非依存。
ストリーム可。
<li> 欠点:
巨大になるとエディタでは見にくい。
シーク不可。書き換え不可。
</ul>

<h4>XML</h4>
<ul>
<li> 利点:
複雑な階層構造をもったデータ向け。テキスト。言語非依存。
<li> 欠点:
巨大になるとエディタでは見にくい。
シーク不可。書き換え不可。
</ul>

<h4>SQLite</h4>
<ul>
<li> 利点:
型が決まっているデータ向け。
言語非依存。
4Gぐらいのデータまでなら余裕。
シーク可。書き換え可。堅牢。
<li> 欠点:
あらかじめテーブルの設計が必要。
ツールを使わないと見れない。
</ul>

<h4>SQLite + JSON</h4>
<p>
複雑な構造 × 膨大な数があるときに使う方法。

<h3>4.5. もっと高度な方法</h3>
<p>
ProtocolBuffer, HDF, MongoDB, ...
<p>
導入に手間がかかりすぎて、個人でやる実験には向かない。


<h2 id="python">5. Python から CSV/JSON/SQLite を使う</h2>

<h3>5.1. CSV</h3>
<h4>書き込み</h4>
<blockquote><pre>
import csv
with open('output.csv', 'w') as fp:
    writer = csv.writer(fp)
    writer.writerow(['a', 'b', 'ccc'])
</pre></blockquote>

<h4>読み込み</h4>
<blockquote><pre>
import csv
with open('input.csv') as fp:
    for row in csv.reader(fp):
        print(row)
</pre></blockquote>

<h3>5.2. JSON</h3>
<h4>書き込み</h4>
<blockquote><pre>
import json
with open(output.json') as fp:
    data = {'a':123, b:['x','y']}
    fp.write(json.dumps(data))
</pre></blockquote>

<h4>読み込み</h4>
<blockquote><pre>
import json
with open('input.json') as fp:
    for line in fp:
        data = json.loads(line)
</pre></blockquote>

<h3>5.3. SQLite</h3>

<h4>書き込み</h4>
<blockquote><pre>
import sqlite3
db = sqlite3.connect('data.db')
cur = db.cursor()
cur.executescript('''
CREATE TABLE Student (
    Id INTEGER PRIMARY KEY,
    Name TEXT,
    Score INTEGER);
''')
for (name,id,score) in scores:
    cur.execute('INSERT INTO Student VALUES (?, ?, ?);', name, id, score)
</pre></blockquote>

<h4>読み込み</h4>
<blockquote><pre>
import sqlite3
db = sqlite3.connect('data.db')
cur = db.cursor()
for row in cur.execute('SELECT Name,Id FROM Student;'):
    (name,id) = row
</pre></blockquote>

<h2 id="vsm">6. Vector Space Model を使った類似度計算</h2>
<p>
Vector Space Model (VSM) とは離散的な素性からなる
データの類似度を計算する簡単な方法である。
<div class=exp>
A = {a<sub>i</sub>}, B = {b<sub>i</sub>}
</div>
というデータがあるとき、簡単な方法では:
<div class=exp>
Jaccard係数 = (A &cap; B) / (A &cup; B)
</div>
<p>
VSM はこれをもうちょっと高度にしたもので、
各素性の「重み (頻度)」を考慮する。
これはようするに
{a<sub>i</sub>}, {b<sub>i</sub>} の各要素を並べ、これを
ベクトルとしてみたときの cosine距離である:
<div class=exp>
類似度 = &Sigma; (a<sub>i</sub> &times; b<sub>i</sub>) /
&radic; (&Sigma; |a<sub>i</sub>|<sup>2</sup>) &times;
&radic; (&Sigma; |b<sub>i</sub>|<sup>2</sup>)
</div>
<p>
これがなぜうまくいくのかは、次の例を考えてみるとわかる。
<p>
(揃っているときの図)
<p>
(揃ってないときの図)
<p>
さらに、次のようなケースもある:
<p>
(高さが違うときの図)

<h3>6.1. Pythonによる実装</h3>
<p>
各素性の集合からなるベクトルは、Python では辞書 (<code>dict</code>) として
表すのがもっとも自然である。そこで、2つの与えられた辞書オブジェクトから
cosine距離を求めるような関数 <code>calcdot()</code> を作る。

<blockquote><pre>
def calcdot(a, b):
    ...
    return

v1 = {'x':1, 'y':2}
v2 = {'x':2, 'y':1, 'z':3}
print(calcdot(v1, v2))  # 0.47809144373375745
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
上の関数を完成させよ。
</div>

<h3>6.2. 実際のデータへの適用</h3>
<ul>
<li> <a href="enwiki-20140102-10000.txt.gz">Wikipedia英語版の記事データ (10000記事)</a>
</ul>

<div class=q>
<strong>演習a.</strong>
上の記事データをダウンロードし、
各記事中の単語を単純な正規表現で切り出してカウントする
Python プログラムを書け。
このデータは以下のような構造になっている。
<blockquote><pre>
# 2428190 Melbourne Shuffle
The Melbourne Shuffle (also known as Rocking or simply The Shuffle) is
a rave and club dance that originated in the late 1980s in the
underground rave music scene in Melbourne, Australia. The basic
...
(空行)
# 442370 List of prime numbers
By Euclid's theorem, there is an infinite number of prime
numbers. Subsets of the prime numbers may be generated with various
formulas for primes. The first 500 primes are listed below, followed
...
(空行)
</pre></blockquote>
</div>

<h4>ヒント</h4>
<p>
まず文字列を単語のリストに変換する関数 <code>splitwords</code> を考える。
とりあえず、正規表現を使って簡単にやる:
<blockquote><pre>
import re
def splitwords(text):
    return [ w.lower() for w in re.findall(r'\w+', text) ]
</pre></blockquote>
<p>
つぎに上の <code>doit()</code> を改良して、
読み込みんだデータファイルを解析する:
<blockquote><pre>
def doit(args):
    for line in fileinput.input(args):
        line = line.strip()
        if line.startswith('#'):
            (artid, _, title) = line[2:].partition(' ')
            artid = int(artid)
        elif line:
            <span class=comment># 単語に区切る。</span>
            words = splitwords(line)
        else:
            <span class=comment># この時点で artid, title, words が設定されているはず。</span>
            print(artid, title, words)
            <span class=comment># 各単語の頻度情報を格納した辞書 wordcount を求める。</span>
            wordcount = countwords(words)
</pre></blockquote>
<p>
gzip圧縮されたデータを読み込むには、以下のようにする手もあるが:
<blockquote><pre>
$ <strong>gzip -dc enwiki-20140102-10000.txt.gz | python doit.py</strong>
</pre></blockquote>
<p>
Pythonの<code>fileinput</code>にオプションを与えると、gzipをそのまま読み込むことができる。
(ただし、UTF-8をデコードする必要があるので注意!)
<blockquote><pre>
    for line in fileinput.input(args, <mark>openhook=fileinput.hook_compressed</mark>):
        ...
</pre></blockquote>

<div class=q>
<strong>演習b.</strong>
各記事ID, 記事タイトルおよび a. でカウントした頻度情報 (JSON形式) を
入れる SQLテーブルを設計し、SQLiteを使って10000記事ぶんの情報を
格納したデータベースを作成せよ。
</div>

<h4>ヒント</h4>
<p>
まずSQLiteのテーブルを作成しよう。
<blockquote><pre>
db = sqlite3.connect('articles.db')
cur = db.cursor()
cur.executescript('''
CREATE TABLE Article (
    ArtId INTEGER PRIMARY KEY,
    Title TEXT,
    Words TEXT);
''')
</pre></blockquote>
<p>
ここに、上で求めた <code>(artid, title, wordcount)</code> を INSERT していく。
ただし、<code>wordcount</code> は辞書なので、JSONに変換する:
<blockquote><pre>
cur.execute('INSERT INTO Article VALUES(?,?,?);',
            (artid, title, json.dumps(wordcount)))
<span class=comment># 注意: commitしないとデータは書き込まれない。</span>
db.commit()
</pre></blockquote>

<div class=q>
<strong>演習c.</strong>
上で設計した関数 <code>calcdot()</code> を
10000×10000のベクトル対に適用し、
もっとも高い類似度をもつ記事ペアを表示せよ。
</div>

<h4>ヒント</h4>
<p>
これは別の Python スクリプトにする。
<p>
基本戦略は、すべての記事対 |A| &times; |B| に対して、
<code>calcdot(a,b)</code> を計算し、最高となる a, b を求めればよい:
<blockquote><pre>
articles = [ ... ]
maxsim = 0
maxpair = None
for a in articles:
    for b in articles:
        sim = calcdot(a, b)
        if maxsim &lt; sim:
            maxsim = sim
            maxpair = (a,b)
</pre></blockquote>
<p>
実際には <code>calcdot(a,b) == calcdot(b,a)</code> であることを
利用して、計算時間を半分にする:
<blockquote><pre>
for (i,a) in <mark>enumerate(articles)</mark>:
    for b in <mark>articles[i+1:]</mark>:
        sim = calcdot(a, b)
        ...
</pre></blockquote>
<p>
問題は、<code>articles</code> は巨大で
一度にメモリに読み込みたくないということである。
そこで、まず <code>artid</code> の一覧を取得し
毎回 SQLite から記事のベクトルを読み込むことにする。

<blockquote><pre>
def getarticle(cur, artid):
    for (wordcount,) in cur.execute(
        'SELECT Words FROM Article WHERE ArtId = ?;', (artid,)):
        return json.loads(wordcount)

<span class=comment># すべての Artid のリストを取得。(これは小さい)</span>
artids = [ artid for (artid,) in cur.execute('SELECT ArtId FROM Article;') ]
</pre></blockquote>

<p>
(注意: なお、ここで紹介した方法は完璧ではない。
一般的には、自然言語文の類似度計算には
各単語の出現頻度だけでなく、単語の重み (IDF) も考慮している)

<p>
新山による実装:
<a href="https://github.com/euske/python3-toys/blob/master/vsm.py">https://github.com/euske/python3-toys/blob/master/vsm.py</a>


<h2 id="clustering">7. 類似度をもちいたクラスタリングの実装</h2>
<p>
上で求めた類似度の計算を使って、類似記事をグループ化
(クラスタリング) してみる。ここではもっとも簡単に、
クラスタ間の最短距離 (半径) でまとめることを考える:
<blockquote><pre>
<span class=comment># しきい値</span>
threshold = 0.9

for ...:
    a = getarticle(artid1)
    b = getarticle(artid2)
    sim = calcdot(a, b)
    if threshold &lt; sim:
       <span class=comment># まとめる</span>
       connect(artid1, artid2)
</pre></blockquote>
<p>
関数 <code>connect(p, q)</code> は、すこし複雑である:
<blockquote><pre>
<span class=comment># 各グループの所属を保持する辞書:</span>
groups = {}

def connect(p, q):
    if p in groups and q in groups:
        <span class=comment># p, q 両方が別々のグループに含まれている場合: g[p] と g[q] を統合する。</span>
        g = groups[p]
        g.merge(groups[q])
        <span class=comment># 各要素の所属をつけかえる。</span>
        for x in g.artids:
            groups[x] = g
    elif p in groups:
        <span class=comment># p のみがグループに含まれている場合: q を g[p] に追加する。</span>
        groups[p].add(q)
    elif q in groups:
        <span class=comment># q のみがグループに含まれている場合: p を g[q] に追加する。</span>
        groups[q].add(p)
    else:
        <span class=comment># p, q どちらもグループに含まれていない場合: 新規グループを作成する。</span>
        g = Group()
        g.add(p)
        g.add(q)
        groups[p] = groups[q] = g
</pre></blockquote>
<p>
Group はクラスを使ってこのように定義する。
<blockquote><pre>
class Group:

    def __init__(self):
        self.artids = []
        return

    def add(self, artid):
        self.artids.append(artid)
        return

    def merge(self, group):
        self.artids.extend(group.artids)
        return
</pre></blockquote>

<h2 id="warmup2">7.99. ウォームアップ問題 (その2)</h2>
<p>
CSV ファイルを以下のような JSON 形式に変換する
スクリプト <code>csv2json.py</code> を書け。
<ul>
<li> <a href="picnic.csv">picnic.csv</a>
<li> <a href="picnic.json">picnic.json</a>
</ul>

<h2 id="dtree">8. Python による決定木の実装</h2>
<p>
決定木は、少数の素性 (〜1000個程度) のみからなる
データを学習したいときに有用である。
<h4>利点</h4>
<ul>
<li> 誰でも実装できる。
<li> 一度学習してしまえばメチャクチャ高速。
</ul>
<h4>欠点</h4>
<ul>
<li> 過学習しやすい。
<li> 確からしさを出したいときには使えない。
</ul>

<h4>基本的な手順</h4>
<ol>
<li> 使う素性をいっこ選び、その素性を使った 「split」を列挙する。
<li> もっとも相対エントロピーが高い split を選択する。
<li> 再帰的に split を繰り返す。
</ol>

<h3>8.1. 準備</h3>
<p>
まず、学習する対象のモノ (オブジェクト) を
Python でどのように表すかを決定する。
オブジェクトは基本的に素性の集合なので、
ここでは単に Python の辞書を使う。

<blockquote><pre>
obj = {'Temperature': 'High', 'Wind': 'Strong' }
</pre></blockquote>

つぎに <code>Feature</code> (素性) クラスを設計する:
<blockquote><pre>
class Feature:

    def __init__(self, attr):
        self.attr = attr
        return

    <span class=comment># 与えられたオブジェクトから素性を取り出す。</span>
    def ident(self, obj):
        return obj[self.attr]

    <span class=comment># 与えられたオブジェクト列をこの素性で分割する。</span>
    def split(self, objs):
        raise NotImplementedError  <span class=comment># 未実装</span>
</pre></blockquote>

<p>
こうすると何が嬉しいかというと、
「素性」というものを抽象的に定義することで、
あとあと別のタイプの素性 (連続的な量を表す素性など) に
拡張できるためである。

<blockquote><pre>
&gt;&gt;&gt; f = Feature('Temperature')  <span class=comment># 素性 Temperature を定義する。</span>
&gt;&gt;&gt; f.ident(obj)                <span class=comment># obj からその素性を取り出す。</span>
'High'
</pre></blockquote>

<p>
つぎに、作成する決定木をあらわす抽象クラス <code>Node</code> を設計する:

<blockquote><pre>
class Node:

    <span class=comment># 与えられたオブジェクトに対する判定結果を返す。</span>
    def test(self, obj):
        raise NotImplementedError  <span class=comment># 未実装</span>
</pre></blockquote>

<p>
実際には、決定木は再帰的な構造をもっていて、
これは <code>Branch</code> と <code>Leaf</code> に分けられる。
それぞれを実装する:

<blockquote><pre>
class Leaf(Node):

    def __init__(self, answer):
        self.answer = answer
        return

    <span class=comment># 与えられたオブジェクトに対する判定結果を返す。</span>
    def test(self, obj):
        <span class=comment># これは木の終端なので、すでに答えは決まっている。</span>
        return self.answer

class Branch(Node):

    def __init__(self, feature, children):
        self.feature = feature
        self.children = children
        return

    <span class=comment># 与えられたオブジェクトに対する判定結果を返す。</span>
    def test(self, obj):
        <span class=comment># 決められた素性を使って、子ノードのいずれかを選ぶ。</span>
        v = self.feature.ident(obj)
        branch = self.children[v]
        <span class=comment># 子ノードにオブジェクトを渡して予測させる。</span>
        return branch.test(obj)
</pre></blockquote>

<p>
ひとつのオブジェクト obj はルート <code>Branch</code> から始まって、
次々に <code>test(obj)</code> に渡されていく。
木を下るにしたがって、いずれ <code>Leaf</code> ノードに到達する。
<code>Leaf</code> ノードはつねに決まった値を返すので、
この時点で判定結果が決まることになる。

<p>
ここで先ほどの抽象的な <code>Feature</code> クラスを継承し、
離散的な素性を扱うための <code>DiscreteFeature</code>
クラスを実装する:
<blockquote><pre>
class DiscreteFeature(Feature):

    <span class=comment># 与えられたオブジェクト列をこの素性で分割する。</span>
    def split(self, objs):
        assert 2 &lt;= len(objs)
        <span class=comment># 自分の素性に従って objs を分割する。</span>
        d = {}
        for obj in objs:
            v = self.ident(obj)
            if v in d:
                a = d[v]
            else:
                a = d[v] = []
            a.append(obj)
        <span class=comment># この時点で</span>
        <span class=comment># d = { 値1: [オブジェクト, オブジェクト, ...],</span>
        <span class=comment>#       値2: [オブジェクト, オブジェクト, ...],</span>
        <span class=comment>#       ... }</span>
        <span class=comment># 各項目の平均エントロピーを計算する。</span>
        n = len(objs)
        ent = sum( len(a) * calcent(a) for a in d.values() ) / n
        <span class=comment># 平均エントロピーと分割結果を返す。</span>
        return (ent, d)
</pre></blockquote>

<h3>8.2. エントロピーの計算</h3>
<p>
ある分布をもつ確率変数 P のエントロピーは次の式で表される:
<div class=exp>
E(P) = &Sigma; -<em>p</em> &times; log(<em>p</em>)
</div>

<p>
ここで、与えられたオブジェクト列に対するエントロピーを
計算する関数 <code>calcent(objs)</code> を作成する。
ここでいう「オブジェクト列に対するエントロピー」とは、
実際には<strong>判定結果のエントロピー</strong>のことであるので、
まず学習データの各オブジェクトのどこに判定結果が入っているかを
あらかじめ決めておく。
ここでは <code>obj['answer']</code> に入っているとしよう。
(なお log の底は自然対数でもよいが、2 を使うほうがわかりやすい)

<blockquote><pre>
<span class=comment># 与えられた学習データ objs のエントロピーを計算する。</span>
def calcent(objs):
    answers = [ obj['answer'] for obj in objs ]
    probs = []
    ...
    return sum( -p*log2(p) for p in probs )
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
上の関数 <code>calcent()</code> を完成させよ。
</div>

<h3>8.3. 決定木の構築</h3>
<p>
以上の準備ができたら、実際に
与えられた素性 <code>feats</code> と学習データ <code>objs</code> から
決定木を構築する関数 <code>buildtree</code> を作成する。
<blockquote><pre>
<span class=comment># buildtree:</span>
<span class=comment>#   素性の集合 feats を使って、オブジェクト列 objs を分類する決定木を返す。</span>
def buildtree(feats, objs):
    <span class=comment># これ以上分岐しても意味がない場合は Leaf を返す。</span>
    if calcent(objs) &lt; EPSILON:
        return Leaf(getbest(objs))
    <span class=comment># objs をもっともよく分割するような素性を探す。</span>
    minent = 9999
    minfeat = None
    minsplit = None
    for feat in feats:
        (ent, split) = feat.split(objs)
        if ent &lt; minent:
            <span class=comment># もっともエントロピーが少ない時の feat と split を記録。</span>
            minent = ent
            minfeat = feat
            minsplit = split
    assert minsplit is not None
    <span class=comment># split の各結果に対してさらに部分木を構築する。</span>
    children = {}
    for (v,a) in minsplit.items():
        children[v] = buildtree(feats, a)
    return Branch(minfeat, children)
</pre></blockquote>
<p>
変数 feats にはあらかじめ定義した <code>Feature</code> の列を与える。
picnic.csv の場合、これは "Outlook", "Temp", "Humidity", "Wind" の
4種類を与えればよい。
<blockquote><pre>
Day,Outlook,Temp,Humidity,Wind,Decision
1,Sunny,Hot,High,Weak,No
2,Sunny,Hot,High,Strong,No
3,Overcast,Hot,High,Weak,Yes
...
</pre></blockquote>

<blockquote><pre>
feats = [
    DiscreteFeature('Outlook'),
    DiscreteFeature('Temp'),
    DiscreteFeature('Humidity'),
    DiscreteFeature('Wind')
]
tree = buildtree(feats, objs)
</pre></blockquote>

<h3>8.4. 決定木を使う</h3>
<p>
完成した決定木を使うには、トップの
<code>Node.test()</code> メソッドに判定したい
オブジェクト (素性の集合) を渡せばよい。
子ノードの <code>test()</code> が再帰的に呼ばれ、
解が決定される。
<blockquote><pre>
obj = {'Outlook': 'Sunny', 'Temp': 'Hot', 'Humidity': 'High', 'Wind': 'Weak'}
print(tree.test(obj))
</pre></blockquote>

<div class=q>
<strong>演習.</strong>
<code>picnic.csv </code> のデータを使って決定木を学習し、
実際に適用せよ。
</div>

<p>
実際には、学習した <code>Leaf</code> / <code>Branch</code> オブジェクトを
ファイルに保存しておき、あとで使うといった工夫が必要になる。

<p>
新山による実装:
<a href="https://github.com/euske/python3-toys/blob/master/dtree.py">https://github.com/euske/python3-toys/blob/master/dtree.py</a>


<h2 id="naivebayes">9. Python による Naive Bayes の実装</h2>
<p>
Naive Bayes 法は、離散的な少数の素性 (〜1000個程度)
のみからなるデータを学習したいときに有用である。
<h4>利点</h4>
<ul>
<li> 学習が簡単 (数えるだけ)。
<li> 確率の異なる複数の結果を返せる。
</ul>
<h4>欠点</h4>
<ul>
<li> 複雑な相関関係をもつデータには不向き。
<li> 一度も学習データに表れなかった素性があるとつねに「確率ゼロ」になってしまう。
</ul>

<h3>9.1. 原理</h3>
<ol>
<li> 学習: 素性の集合 <em>F</em> = {<em>f<sub>i</sub></em>} とクラス <em>k</em> に対して、
条件つき確率
P(<em>k</em> | <em>f<sub>1</sub></em>, <em>f<sub>2</sub></em>, ..., <em>f<sub>n</sub></em>) を計算する。
<li> 予測: <em>F</em> が与えられたら、
argmax<em><sub>k</sub></em> P(<em>k</em> | <em>F</em>) となるような <em>k</em> を求める。
</ol>
<p>
で、どうやって P(<em>k</em> | <em>F</em>)
を計算するのか? 以下の式を使う。
(Naive <u>Bayes</u> といわれるゆえんである。)
<div class=exp>
P(<em>k</em> | <em>F</em>) = P(<em>k</em>)・P(<em>F</em>|<em>k</em>) / P(<em>F</em>)
</div>
ここで <em>F</em> はあらかじめ与えられているので P(<em>F</em>) は無視できて
<div class=exp>
argmax<em><sub>k</sub></em> P(<em>k</em> | <em>F</em>) =
argmax<em><sub>k</sub></em> P(<em>k</em>)・P(<em>F</em> | <em>k</em>)
</div>
さらに、各素性 <em>f<sub>i</sub></em> と <em>k</em> は相関しているが、
各素性
<em>f<sub>1</sub></em>,  <em>f<sub>2</sub></em>, ...  <em>f<sub>n</sub></em> どうしは
それぞれ <u>独立</u> (independent) して現れると仮定する。つまり
<div class=exp>
P(<em>f<sub>1</sub></em> | <em>f<sub>2</sub></em>) =
P(<em>f<sub>1</sub></em> | <em>f<sub>3</sub></em>) =
...
P(<em>f<sub>1</sub></em> | <em>f<sub>n</sub></em>) =
P(<em>f<sub>1</sub></em>)
</div>
<p>
実際には、この仮定は正しくない。
(<u>Naive</u> Bayes といわれるゆえんである。)
しかしこの仮定により、
<div class=exp>
P(<em>F</em> | <em>k</em>) =
P(<em>f<sub>1</sub></em>, <em>f<sub>2</sub></em>, ..., <em>f<sub>n</sub></em> | <em>k</em>) =
P(<em>f<sub>1</sub></em> | <em>k</em>) ×
P(<em>f<sub>2</sub></em> | <em>k</em>) ×
... ×
P(<em>f<sub>n</sub></em> | <em>k</em>)
</div>
と近似することができる。
P(<em>f<sub>i</sub></em> | <em>k</em>) を求めるのは簡単である。
学習データを見て、各素性 <em>f<sub>i</sub></em> と
それに対応するクラス <em>k</em> が同時に現れる回数をただ数えればよい。
このように、 Naive Bayes では素性と応答の数をただかぞえるだけで
学習が可能である。

<h3>9.2. Python における実装</h3>
<p>
Naive Bayes を実装するには
<ol type=a>
<li> 各クラス <em>k</em> が学習データ中に何回現れたか。
<li> 各クラスと素性の対 (<em>f<sub>i</sub></em>, <em>k</em>) が
  学習データ中に何回現れたか。
</ol>
を記録しておく必要がある。
a. は簡単である。いっぽう b. は、以下のように格納しておくと便利である:
<blockquote><pre>
fcount = {
  クラス1: { 素性a: 回数, 素性b: 回数, ... }
  クラス2: { 素性a: 回数, 素性b: 回数, ... }
  ...
}
</pre></blockquote>
さらに (素性と関係なく) <em>k</em> が現れた回数は、
それ自体をひとつの特殊な素性 <code>ALL</code> とみなせるので
<blockquote><pre>
fcount = {
  クラス1: { ALL: 回数, 素性a: 回数, 素性b: 回数, ... }
  クラス2: { ALL: 回数, 素性a: 回数, 素性b: 回数, ... }
  ...
}
</pre></blockquote>
のようにできる。

<p>
これをふまえて、
<code>NaiveBayes</code> クラスを定義する:

<blockquote><pre>
class NaiveBayes:

    def __init__(self):
        self.fcount = {}  <span class=comment># 素性 (k,f) の出現回数。</span>
        return

    <span class=comment># 素性とクラスの相関をひとつ学習する。</span>
    def learn(self, k, feats):
        <span class=comment># クラス k と同時に現れた素性一覧をとりだす。</span>
        if k in self.fcount:
            fc = self.fcount[k]
        else:
            fc = self.fcount[k] = {}
        <span class=comment># k の数を数える。</span>
        if 'ALL' not in fc:
            fc['ALL'] = 0
        fc['ALL'] += 1
        <span class=comment># (f,k) の数を数える。</span>
        for f in feats:
            if f not in fc:
                fc[f] = 0
            fc[f] += 1
        return
</pre></blockquote>

<h3>9.3. 予測する</h3>
<p>
モデルが学習できたら、予測である。
素性の集合 <code>feats</code> が与えられたら、
各 <em>k</em> に対して
<div class=exp>
P(<em>k</em>)・&Pi; P(<em>f<sub>i</sub></em> | <em>k</em>) =
P(<em>k</em>)・&Pi; {P(<em>f<sub>i</sub></em>, <em>k</em>) / P(<em>k</em>)}
</div>
を計算すればよいのであるが、実際には
母数 <code>N</code> が同じなのでこれは確率である必要がない。
<pre class=exp>
fcount[k]['ALL'] * &Pi; (fcount[k][f] / fconut[k]['ALL'])
</pre>
だけで済んでしまう。
さらに、あらかじめ <code>kcount</code> と <code>fcount</code> の log を記録しておき
<pre class=exp>
log(fcount[k]['ALL']) + &Sigma; (log(fcount[k][f]) - log(fconut[k]['ALL']))
</pre>
のようにすれば加減算だけでよくなる。
これをふまえて、メソッド <code>predict()</code> を設計する:
<blockquote><pre>
class NaiveBayes:
    ...

    <span class=comment># 与えられた素性から推定される各クラスの確率を返す。</span>
    def predict(self, feats):
        klass = []
        for (k,fc) in self.fcount.items():
            <span class=comment># P(<em>k</em>)・P(<em>f<sub>i</sub></em> | <em>k</em>) を計算する。</span>
            pk = log(fc['ALL'])
            p = (pk + sum( (log(fc[f]) - pk) for f in feats ))
            klass.append((p, k))
        <span class=comment># クラスの一覧を確率の大きい順にソートする。</span>
        klass.sort(reverse=True)
        return klass
</pre></blockquote>

<p>
この方法がよいのは、結果が確率 (のlog) つきで
返されるということである。
もっとも確実な予想だけを知りたければ <code>klass[0]</code> を使えばよいし、
第2候補も欲しければ <code>klass[1]</code> も見ればよい。
複数の候補が返されるのは Naive Bayes の大きな利点である。

<h4>注意点</h3>
<p>
決定木における「素性」とは、何がしかの値を持つものであったが、
Naive Bayes における「素性」は、実際には「存在するか否か」
という二値的なものであることに注意。
したがって、 <code>picnic.csv</code> のようなデータを使うには、
各素性を "<code>Outlook=Sunny</code>" のように
まるごと文字列として表してやる必要がある。
つまり「素性 <code>Outlook</code> の値が
"<code>Sunny</code>" / "<code>Overcast</code>" / "<code>Rain</code>" のどれかだ」と
考えるのではなく、
「"<code>Outlook=Sunny</code>"、
"<code>Outlook=Overcast</code>"、
"<code>Outlook=Rain</code>" という別々の素性が存在する」
と考えるのである。
当然、<code>Outlook</code> の値が排他的だという情報は
Naive Bayes にはわからない。したがって Naive Bayes は
「"<code>Outlook=Sunny</code>" かつ "<code>Outlook=Overcast</code>"」
というありえない状況も排除しない。
これは独立性の仮定を置いたことによる帰結で、
Naive Bayes 法の限界である。

<div class=q>
<strong>演習.</strong>
同じく、上で示した
<code>picnic.csv </code> のデータを今度は
<code>NaiveBayes</code> クラスに適用し、結果を観察せよ。

<blockquote><pre>
nb = NaiveBayes()
FEATS = ( 'Outlook', 'Temp', 'Humidity', 'Wind' )
for obj in objs:
    <span class=comment># オブジェクトの各素性の値を、二値的な素性に変換する。</span>
    feats = [ f'{k}={obj[k]}' for k in FEATS ]
    <span class=comment># Decision の値と各素性との相関を学習する。</span>
    nb.learn(obj['Decision'], feats)
</pre></blockquote>
</div>

<p>
新山による実装:
<a href="https://github.com/euske/python3-toys/blob/master/naivebayes.py">https://github.com/euske/python3-toys/blob/master/naivebayes.py</a>

<h3>9.4. スムージング</h3>
<p>
実際に上の例を実行してみると、
3番目のオブジェクトのあたりで
「"<code>Outlook=Overcast</code>" という素性が存在しない」
という <code>KeyError</code>例外が発生してしまう。
これは P(<code>No</code> | <code>Outlook=Overcast</code>) の
確率を計算しようとしたことによる。
(<code>fcount['No']</code> の <code>fc</code> 中には
<code>Outlook=Overcast</code> というキーが存在しない。)
これは Naive Bayes を使うさいによく現れる問題で、
このような学習データが存在しなかったのであるから、
そもそも確率を計算できないのである。
<p>
このような場合、逃げの一種として
「素性の各出現回数に 1 を出す」という方法がある。
いわゆる "<a href="https://en.wikipedia.org/wiki/Additive_smoothing">Laplace smoothing</a>" である。
これは Python のコード上では、
<code>fc[f]</code> でキーが存在しなかったときに
<code>1</code> を返すように実装するだけである。

<blockquote><pre>
<span class=comment># 使用前</span>
p = (pk + sum( (log(fc[f]) - pk) for f in feats ))
<span class=comment># 使用後</span>
p = (pk + sum( (log(<mark>fc.get(f,0)+1</mark>) - pk) for f in feats ))
</pre></blockquote>

<hr>
<address>Yusuke Shinyama</address>
